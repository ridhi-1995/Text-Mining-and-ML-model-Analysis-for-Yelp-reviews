{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48084b97",
   "metadata": {},
   "source": [
    "# Data Science Assignment_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05604e4",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr><td><b>Name : Ridhi Sharma</b></td></tr>\n",
    "    <tr><td><b>Student Number : 21201977</b></td></tr>\n",
    "    <tr><td><b>Review DB URL : http://mlg.ucd.ie/modules/python/assign2/21201977/\"</b></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3da9b57",
   "metadata": {},
   "source": [
    "The objective of this assignment is to scrape a collection of product reviews from a set of web pages, preprocess the data, and evaluate the performance of different classifiers in the context of two related text classification tasks: (i) predicting review sentiment; (ii) predicting review helpfulness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf626e2",
   "metadata": {},
   "source": [
    "### This notebook covers Task 2 -  Review Sentiment Classification and Task 3 -  Review Helpfulness Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75002d49",
   "metadata": {},
   "source": [
    "In this notebook, we are going to first assign class values according to ratings and helpfulness information given to us and then train the model based on different binary classifiers.<br>\n",
    "We will be analyzing the below steps:<br>\n",
    "**1. Text preprocessing:** <br>\n",
    "    a. This we will do by filtering the text documents<br>\n",
    "    b. Applying a custom tokenizer to handle stemming and lemming<br>\n",
    "    c. Applying vectorization of two types count and tfidf<br>\n",
    "**2. Classification:** <br>\n",
    "    a. Hold-out Strategy, for this we will create a train-test split apply the model on a training set, and predict the results of testing data test.<br>\n",
    "    b. Cross-Validation, in this we will take the whole data set and perform 'n' number of folds and calculate the accuracy.<br>\n",
    "    c. Pipe-line, this a method where we can combine the text pre-processing and classification.<br>\n",
    "**3. Comparision** <br> \n",
    "    Then we would be comparing different classifiers using the above techniques for Sentiment and Helpfulness Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74783e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries used\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfff5e9",
   "metadata": {},
   "source": [
    "Path to read review.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "008b2ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for raw data storage\n",
    "dir_raw = Path(\"raw\")\n",
    "filePath_raw = dir_raw/\"reviwes.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf0b9df",
   "metadata": {},
   "source": [
    "Below code is used to allign the plots in the centre of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135750bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e8b49",
   "metadata": {},
   "source": [
    "First we read the .csv file as a dataframe which will simplify our analysis further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92a5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_reviews = pd.read_csv(filePath_raw) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f71d697",
   "metadata": {},
   "source": [
    "## Part-2 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc47682",
   "metadata": {},
   "source": [
    "### Assigning Class Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa242307",
   "metadata": {},
   "source": [
    "Defined a function to assign sentiments based on the rating, we were provided with the information to assume that 1-star to 3-star reviews are “negative”, and 4-star to 5-star reviews are “positive”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd7c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_sentiments(df):\n",
    "    Sentiments = []\n",
    "    for row in df[\"Rating\"]:\n",
    "        if row < 3: Sentiments.append(\"Negative\")\n",
    "        else: Sentiments.append(\"Postive\")\n",
    "    df['Sentiments'] = Sentiments\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab9dcb",
   "metadata": {},
   "source": [
    "We now create a new data frame with Sentiment values for Part-2 Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa93f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save this data frame for sentiments for each analysis\n",
    "df_reviews_sentiments= assign_sentiments(dataframe_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c5b0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main Title</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Helpfulness Information</th>\n",
       "      <th>Review Body</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product Reviews Archive January 2016</td>\n",
       "      <td>The herbs were great...but the cherry tomatoes...</td>\n",
       "      <td>2</td>\n",
       "      <td>88.235294</td>\n",
       "      <td>The herb kit that came with my Aerogarden was ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product Reviews Archive January 2016</td>\n",
       "      <td>Even more useful than regular parchment paper</td>\n",
       "      <td>5</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>I originally bought this just because it was c...</td>\n",
       "      <td>Postive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product Reviews Archive January 2016</td>\n",
       "      <td>Shake it before you bake it</td>\n",
       "      <td>2</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>If you do it in reverse (bake before shaking),...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Product Reviews Archive January 2016</td>\n",
       "      <td>Not what the picture describes</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>I bought this steak for my father in law for C...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Main Title  \\\n",
       "0  Product Reviews Archive January 2016   \n",
       "1  Product Reviews Archive January 2016   \n",
       "2  Product Reviews Archive January 2016   \n",
       "3  Product Reviews Archive January 2016   \n",
       "\n",
       "                                        Review Title  Rating  \\\n",
       "0  The herbs were great...but the cherry tomatoes...       2   \n",
       "1      Even more useful than regular parchment paper       5   \n",
       "2                        Shake it before you bake it       2   \n",
       "3                     Not what the picture describes       2   \n",
       "\n",
       "   Helpfulness Information                                        Review Body  \\\n",
       "0                88.235294  The herb kit that came with my Aerogarden was ...   \n",
       "1               100.000000  I originally bought this just because it was c...   \n",
       "2                15.384615  If you do it in reverse (bake before shaking),...   \n",
       "3                50.000000  I bought this steak for my father in law for C...   \n",
       "\n",
       "  Sentiments  \n",
       "0   Negative  \n",
       "1    Postive  \n",
       "2   Negative  \n",
       "3   Negative  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_sentiments[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578a719",
   "metadata": {},
   "source": [
    "Now we create a data frame as a set of documents, where each row is a concatenation of the review’s title and body text and has a class value same as sentiments. This will be our main data set to deal with for Part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af66eeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The herbs were great...but the cherry tomatoes...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Even more useful than regular parchment paper ...</td>\n",
       "      <td>Postive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shake it before you bake it If you do it in re...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not what the picture describes I bought this s...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text     Class\n",
       "0  The herbs were great...but the cherry tomatoes...  Negative\n",
       "1  Even more useful than regular parchment paper ...   Postive\n",
       "2  Shake it before you bake it If you do it in re...  Negative\n",
       "3  Not what the picture describes I bought this s...  Negative"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define a new data frame for classification\n",
    "df_text_sentiments = pd.DataFrame({\"Review Text\": df_reviews_sentiments[\"Review Title\"]+\" \"+df_reviews_sentiments[\"Review Body\"]\n",
    "                            ,\"Class\":df_reviews_sentiments[\"Sentiments\"]})\n",
    "df_text_sentiments[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c70fa85",
   "metadata": {},
   "source": [
    "For classification purpose we need a list of documents and the class labels as separate variables to handle and for easy representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f76cabcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the corresponding documents and class labels to use for classification\n",
    "documents_sentiments = df_text_sentiments[\"Review Text\"]\n",
    "target_names_sentiments = df_text_sentiments[\"Class\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd12bb4",
   "metadata": {},
   "source": [
    "### Text Analysis - Tokenizing Text and Bag of words representation\n",
    "Tokenization helps in creating tokens for words and also removes unwanted punctuation from the text, as for us in this analysis we don't care if there are any punctuation. But this may not a case for every analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "742070d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'herbs', 'were', 'great', 'but', 'the', 'cherry', 'tomatoes', 'not', 'so', 'great', 'the', 'herb', 'kit', 'that', 'came', 'with', 'my', 'aerogarden', 'was', 'superb', 'and', 'enjoyed', 'caring', 'for', 'my', 'little', 'garden', 'once', 'it', 'was', 'time', 'to', 'replace', 'it', 'purchased', 'the', 'cherry', 'tomato', 'seed', 'kit', 'these', 'also', 'grew', 'rapidly', 'but', 'one', 'day', 'noticed', 'that', 'they', 'had', 'completely', 'fallen', 'over', 'how', 'would', 'stake', 'these', 'on', 'an', 'aerogarden', 'and', 'yes', 'the', 'lights', 'were', 'as', 'close', 'to', 'the', 'plants', 'as', 'possible', 'kind', 'of', 'leaned', 'them', 'against', 'each', 'other', 'to', 'keep', 'them', 'upright', 'but', 'they', 'still', 'fell', 'over', 'several', 'times', 'so', 'they', 'grew', 'and', 'grew', 'but', 'never', 'got', 'any', 'tomatoes', 'also', 'did', 'follow', 'the', 'directions', 'to', 'ensure', 'that', 'they', 'had', 'complete', 'darkness', 'for', 'proper', 'flowering', 'fortunately', 'we', 'have', 'several', 'tomato', 'and', 'cherry', 'tomato', 'plants', 'in', 'our', 'outdoor', 'vegetable', 'garden', 'unfortunately', 'spent', '20', 'on', 'cherry', 'tomato', 'aerogarden', 'plants', 'and', 'got', 'zero', 'yield']\n"
     ]
    }
   ],
   "source": [
    "#just to check the types of words which are present in the document\n",
    "doc1= documents_sentiments[0]\n",
    "tokenize = CountVectorizer().build_tokenizer()\n",
    "# convert to lowercase, then tokenize\n",
    "tokens1 = tokenize(doc1.lower())\n",
    "print(tokens1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849fd6d",
   "metadata": {},
   "source": [
    "We can see that many of the words here are not useful (e.g. \"to\", \"the\" etc.). So we remove such words using a list of such *stop words* which is provided by scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "031bb81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining stop words\n",
    "stopwords = text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505dad71",
   "metadata": {},
   "source": [
    "But now before tokenizing the docucment again, we will filter the document as there are many words like \"ha\", \"te\", which are really not useful, so we remove these words by checking the lenght of words and words having lenght less than 2 have been removed, we have also observed that there are unwanted numbers which we have removed by using re.sub by passing a regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc798b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition to filter documents.\n",
    "def filter_doc(doc):\n",
    "    filtered_document=[]\n",
    "    for sen in range(0, len(doc)):\n",
    "        #removing numbers, words with any numbers and extra spaces.\n",
    "        document= re.sub(r'[0-9]+', ' ',doc[sen])\n",
    "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "        # Converting to Lowercase\n",
    "        document = document.lower()  \n",
    "        document = document.split()\n",
    "        #removing words less than 2 letters.\n",
    "        document = ' '.join([w for w in document if len(w)>2])\n",
    "        filtered_document.append(document)\n",
    "    print(\"Created %d filtered document lists\" % len(filtered_document) )\n",
    "    return filtered_document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3103fc8",
   "metadata": {},
   "source": [
    "We now store this document as filtered document, we can use this similar function for part-3 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "335d5aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 9244 filtered document lists\n"
     ]
    }
   ],
   "source": [
    "#set of filtered documents\n",
    "filtered_document_senti=filter_doc(documents_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c3f46",
   "metadata": {},
   "source": [
    "Now we tokenize the whole set of documents and store this tokens as filtered tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bb304f",
   "metadata": {},
   "source": [
    "### Text Preprocessing and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b8485f",
   "metadata": {},
   "source": [
    "So firstly, when trying to stem the documents using CountVectorizering the set of documents had a few stop words felt that were not consistent and were not been removed while vectorizing the text, so for this we need to include those stop words into our tokenization process and then remove it later. <br>\n",
    "**CountVectorizer** is used to convert text into a vector based on the frequency or count of each word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1bcb42",
   "metadata": {},
   "source": [
    "**Stemming**: Stemming is a process to reduce the word its root by removing a part of it, for example, if we have ask, asked and asking it will remove the ending as 'ed' and 'ing' and convert both of them to 'ask'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "502fdda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function for stemming\n",
    "def stem_tokenizer(text):\n",
    "    # use the standard scikit-learn tokenizer first\n",
    "    standard_tokenizer = CountVectorizer().build_tokenizer()\n",
    "    #create tokens based on countVectorizer\n",
    "    tokens = standard_tokenizer(text)\n",
    "    # then use NLTK to perform stemming on each token\n",
    "    stemmer = PorterStemmer()\n",
    "    filtered_tokens=[]\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "     # to remove stopwords with tokenization\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens if t not in stopwords]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81daaa01",
   "metadata": {},
   "source": [
    "### Term Frequency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa258ec0",
   "metadata": {},
   "source": [
    "We now define our CountVectorize function based on our stem tokenizer we have also removed words with frequency less than 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212b9190",
   "metadata": {},
   "source": [
    "We also create a vectorize data data set for term frequency analysis and this can be used futher for applying ***cross validation*** as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e0b6932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9244, 4161)\n"
     ]
    }
   ],
   "source": [
    "#vectorize the filetered documents\n",
    "vectorizer_senti = CountVectorizer(stop_words=\"english\", min_df = 10, tokenizer=stem_tokenizer)\n",
    "X_data_senti = vectorizer_senti.fit_transform(filtered_document_senti)\n",
    "print(X_data_senti.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe8878c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary has 4161 distinct terms\n"
     ]
    }
   ],
   "source": [
    "#Count the terms in vectoried document\n",
    "terms_senti = vectorizer_senti.get_feature_names()\n",
    "print(\"Vocabulary has %d distinct terms\" % len(terms_senti))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1289c3",
   "metadata": {},
   "source": [
    "### Measuring Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cd78a",
   "metadata": {},
   "source": [
    "We can now measure the similarity of document, as part of test analysis, using finding the cosine angle between two documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22371948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the herbs were great...but the cherry tomatoes...not great the herb kit that came with aerogarden was superb and enjoyed caring for little garden. once was time replace it, purchased the cherry tomato seed kit. these also grew rapidly, but one day noticed that they had completely fallen over...how would stake these aerogarden? and yes, the lights were close the plants possible. kind leaned them against each other keep them upright. but they still fell over several times. they grew and grew but never got any tomatoes. also did follow the directions ensure that they had complete darkness for proper flowering. fortunately have several tomato and cherry tomato plants our outdoor vegetable garden. unfortunately, spent cherry tomato aerogarden plants and got zero yield.\n"
     ]
    }
   ],
   "source": [
    "# first document - just display the start of it\n",
    "print(filtered_document_senti[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b95d23a",
   "metadata": {},
   "source": [
    "We will have to vectorize our document to filter out the unwanted words and then and then measure the similarity based on those vectorized documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "413a03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure the cosine similarity between the first document vector and all of the other document vectors\n",
    "max_cos = 0\n",
    "best_row = 0\n",
    "for row in range(1,X_data_senti.shape[0]):\n",
    "    cos = cosine_similarity(X_data_senti[0], X_data_senti[row])\n",
    "    # best so far?\n",
    "    if cos > max_cos:\n",
    "        max_cos = cos\n",
    "        best_row = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd06693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar document was row 24: cosine similarity = 0.528\n"
     ]
    }
   ],
   "source": [
    "print(\"Most similar document was row %d: cosine similarity = %.3f\" % (best_row, max_cos) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a66340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looks like cherry tomato reviews are negative working second cherry tomato seed kit. after about three months, the first crop provided about eight cherry tomatoes. hardly bumper crop. during the growth had clean out the pump which got clogged with roots (more that latter). figured, ok, had disturb the root system when had clean out the pump, perhaps that was the problem. started second crop cherry tomatoes about three months ago. far, have had one marble sized yellow tomato. also have additional two, marble sized, yellow tomatoes ripening. have not even seen any flowers the two red tomato plants. the red tomato plants grow, but tomato production. running out plant nutrients. checked aerogrows site, and they want ridiculous price for additional package plant nutrients. corporate greed its worse. have read all the reviews, and see that about one-third the cherry tomato reviews are positive. that leaves two-thirds cherry tomato reviews negative. adding negative cherry tomato review drops the positive cherry tomato reviews positive, negative. given that are all growing these things under pretty well controlled conditions, suggest that the cherry tomato seed kits might have limited shelf life, and aerogrow could selling their old kits. negative review aerogrow's cherry tomato seed kit their site was not published. published review superstore. with respect the aerogrow garden, opinion, the location the pump flawed. should not located the bottom the tank because that where the roots want go. the pump should located higher the tank, and should located position where can easily maintained, without damaging your crops. hope someone else comes out with competitive product. frankly, don't like the way aerogrow does business.\n"
     ]
    }
   ],
   "source": [
    "# most similar document - just display the start of it\n",
    "print(filtered_document_senti[best_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911423ff",
   "metadata": {},
   "source": [
    "### Train and Test Data Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6962dd0",
   "metadata": {},
   "source": [
    "We now create training data and testing data, using train_test_split function with a **train-test split as 20%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81057327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "train_data_senti, test_data_senti, train_target_senti, test_target_senti = train_test_split(filtered_document_senti, \n",
    "                                                                                            target_names_sentiments, \n",
    "                                                                                            test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d64c280a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 7395 documents. Target classes are {'Postive', 'Negative'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set has %d documents. Target classes are %s\" % (len(train_data_senti), set(train_target_senti)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08e3eb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set has 1849 documents. Target classes are {'Postive', 'Negative'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set has %d documents. Target classes are %s\" % (len(test_data_senti), set(test_target_senti)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1e731",
   "metadata": {},
   "source": [
    "### Train and Test Data Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072db458",
   "metadata": {},
   "source": [
    "We now vectorize the training and the test data set as CountVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3b3d491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7395, 3694)\n"
     ]
    }
   ],
   "source": [
    "#vectorize training data\n",
    "X_train_senti = vectorizer_senti.fit_transform(train_data_senti)\n",
    "print(X_train_senti.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ee38690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['popcorn', 'perfect', 'littl', 'year', 'old', 'son', 'love', 'concern', 'hull', 'potenti', 'choke', 'hazard', 'true', 'free', 'come', 'close', 'tast', 'great', 'opinion', 'kid', 'friendli', 'brand', 'use', 'machin', 'home', 'miss', 'flour', 'lot', 'dens', 'heavier', 'expect', 'make', 'difficult', 'bake', 'decent']\n"
     ]
    }
   ],
   "source": [
    "print(list(vectorizer_senti.vocabulary_.keys())[0:35])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567dc841",
   "metadata": {},
   "source": [
    "For test data we just perform transform to keep the same number of columns of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ebc6675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1849, 3694)\n"
     ]
    }
   ],
   "source": [
    "#vectorize testing data\n",
    "X_test_senti = vectorizer_senti.transform(test_data_senti)\n",
    "print(X_test_senti.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f990c62",
   "metadata": {},
   "source": [
    "### Cross Validation CV=5\n",
    "<br>So firstly, we will apply a cross-validation technique using KNN, which can help us analyze which value of K might be better to take into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dd2d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1 - Mean accuracy=0.744\n",
      "K=3 - Mean accuracy=0.730\n",
      "K=5 - Mean accuracy=0.723\n"
     ]
    }
   ],
   "source": [
    "#cross validation for KNN\n",
    "for k in [1,3,5]:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    # apply 5-fold cross-validation, measuring accuracy each time\n",
    "    acc_scores = cross_val_score(model, X_data_senti, target_names_sentiments, cv=5, scoring=\"accuracy\")\n",
    "    # get the mean accuracy across 5 folds\n",
    "    mean_acc = acc_scores.mean()\n",
    "    print(\"K=%d - Mean accuracy=%.3f\" % (k,mean_acc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092554ac",
   "metadata": {},
   "source": [
    "### KNN=3 using Hold-out Startergy\n",
    "We will now build KNN using K= 3, as K = 1 is not ideal and K=5 has less accuracy and calculate the accuracy and other methods of accuracy for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8a838d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a KNN model on the document-term matrix created from the original set of documents\n",
    "model_KNN_senti = KNeighborsClassifier(n_neighbors=3)\n",
    "model_KNN_senti.fit(X_train_senti, train_target_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7109b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted KNN class values\n",
    "predicted_Senti_KNN = model_KNN_senti.predict(X_test_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97d0e80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.735\n"
     ]
    }
   ],
   "source": [
    "#Accuracy for KNN\n",
    "acc_KNN = accuracy_score(test_target_senti, predicted_Senti_KNN)\n",
    "print(\"Classification accuracy = %.3f\" % acc_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3d0718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting target categories\n",
    "target_categories_senti = [\"Positive\",\"Negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f67c7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.60      0.74      0.66       657\n",
      "    Negative       0.83      0.73      0.78      1192\n",
      "\n",
      "    accuracy                           0.73      1849\n",
      "   macro avg       0.72      0.74      0.72      1849\n",
      "weighted avg       0.75      0.73      0.74      1849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#prints classification report with all the accuracy metrics\n",
    "print(classification_report(test_target_senti, predicted_Senti_KNN, target_names=target_categories_senti))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1995403",
   "metadata": {},
   "source": [
    "**Comment:** We can see that the **accuracy is 73.5%** for KNN=3, while we can see that the **precision is less for positive class**, which means the model had difficulty predicting positive class, maybe because the **number of positives must be less than negatives**. While the recall is quite similar for both the classes stating the model was able to cover these classes properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ee311",
   "metadata": {},
   "source": [
    "This being a binary classifier, Precision and Recall plays an important role where,<br>\n",
    "1. **Precision** is the number of correct positive outcomes divided by the classifier's predicted number of positive results.\n",
    "2. **Recall** is calculated by dividing the number of valid positive results by the total number of relevant observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c2cde4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "cm_KNN = confusion_matrix(test_target_senti, predicted_Senti_KNN)\n",
    "# display it graphically\n",
    "cmd = ConfusionMatrixDisplay(cm_KNN, display_labels=target_categories_senti)\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30de77",
   "metadata": {},
   "source": [
    "**Comment:** As the precision was low for the positive class we can see from the confusion matrix that higher number positives were predicted as negatives. The model works good for negative classes but not great for the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141b7412",
   "metadata": {},
   "source": [
    "### Cross Validation CV=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db08d4",
   "metadata": {},
   "source": [
    "As we can see that the accuracy comes out to be similar, for K=3 for cross-validation and normal KNN. We can also check that if we increase the folds of the cross validation how our model would work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b0a4231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1 - Mean accuracy=0.754\n",
      "K=3 - Mean accuracy=0.737\n",
      "K=5 - Mean accuracy=0.731\n"
     ]
    }
   ],
   "source": [
    "#cross validation using KNN\n",
    "for k in [1,3,5]:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    # apply 10-fold cross-validation, measuring accuracy each time\n",
    "    acc_scores = cross_val_score(model, X_data_senti, target_names_sentiments, cv=10, scoring=\"accuracy\")\n",
    "    # get the mean accuracy across 5 folds\n",
    "    mean_acc = acc_scores.mean()\n",
    "    print(\"K=%d - Mean accuracy=%.3f\" % (k,mean_acc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48caa37a",
   "metadata": {},
   "source": [
    "**Comment:** This increases the accuracy but not to that extent so it is better to use 5 folds as using a high number of folds is time-consuming, but if we have large datasets we should try checking 10-cross-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b060245",
   "metadata": {},
   "source": [
    "### Pipeline Classification using SVM<br>\n",
    "Pipeline helps in doing every step together, like data preperation(tokenization) and classification. So below we created a pipeline using SVM classifier and the tokenizer we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edebbbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM pipeline model\n",
    "pipeline_svm_senti = Pipeline([\n",
    "    ('vec', CountVectorizer(stop_words=\"english\", min_df = 10, tokenizer=stem_tokenizer)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56f96ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec',\n",
       "                 CountVectorizer(min_df=10, stop_words='english',\n",
       "                                 tokenizer=<function stem_tokenizer at 0x000001C802E0C9D0>)),\n",
       "                ('tfidf', TfidfTransformer()), ('clf', SGDClassifier())])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit SVM model\n",
    "pipeline_svm_senti.fit(train_data_senti, train_target_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcfdd728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.884\n"
     ]
    }
   ],
   "source": [
    "#predict target class\n",
    "predicted_SVM_Senti = pipeline_svm_senti.predict(test_data_senti)\n",
    "print(\"Classification accuracy = %.3f\" % accuracy_score(test_target_senti, predicted_SVM_Senti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e652f11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.86      0.81      0.83       657\n",
      "    Negative       0.90      0.92      0.91      1192\n",
      "\n",
      "    accuracy                           0.88      1849\n",
      "   macro avg       0.88      0.87      0.87      1849\n",
      "weighted avg       0.88      0.88      0.88      1849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#prints classification report with all the accuracy metrics\n",
    "print(classification_report(test_target_senti, predicted_SVM_Senti, target_names=target_categories_senti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e8178f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "cm_SVM = confusion_matrix(test_target_senti, predicted_SVM_Senti)\n",
    "# display it graphically\n",
    "cmd = ConfusionMatrixDisplay(cm_SVM, display_labels=target_categories_senti)\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a52de59",
   "metadata": {},
   "source": [
    "**Comment:** SVM showed high accuracy when compared to KNN because, it defines the best boundary to separate the class, which enhances itself as a model when compared to others, as we can see that the wrongly classified classes are less in SVM as compared to KNN and precision and recall is also great. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe068f0f",
   "metadata": {},
   "source": [
    "## Part 3-  Review Helpfulness Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33067000",
   "metadata": {},
   "source": [
    "In part of the assignment we will try to work with Helpfulness classification using similar analysis and change if we think we would need some better methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4748717",
   "metadata": {},
   "source": [
    "So, first, we define a function to assign the helpfulness value, for this I assumed if the percentage of helpfulness information is more than 60% then that review is considered helpful. This percentage was sent will collection data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77799e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to assign helpfulness\n",
    "def assign_helpfulness(df):\n",
    "    Helpfulness = []\n",
    "    for row in df[\"Helpfulness Information\"]:\n",
    "        if row < 60: Helpfulness.append(\"Not Helpful\")\n",
    "        else: Helpfulness.append(\"Helpful\")\n",
    "    df['Helpfulness'] = Helpfulness\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1269e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store this data frame as new dataframe for analysis\n",
    "df_reviews_helpfullness= assign_helpfulness(dataframe_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4de938fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main Title</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Helpfulness Information</th>\n",
       "      <th>Review Body</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>Helpfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product Reviews Archive January 2016</td>\n",
       "      <td>The herbs were great...but the cherry tomatoes...</td>\n",
       "      <td>2</td>\n",
       "      <td>88.235294</td>\n",
       "      <td>The herb kit that came with my Aerogarden was ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product Reviews Archive January 2016</td>\n",
       "      <td>Even more useful than regular parchment paper</td>\n",
       "      <td>5</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>I originally bought this just because it was c...</td>\n",
       "      <td>Postive</td>\n",
       "      <td>Helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product Reviews Archive January 2016</td>\n",
       "      <td>Shake it before you bake it</td>\n",
       "      <td>2</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>If you do it in reverse (bake before shaking),...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Not Helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Product Reviews Archive January 2016</td>\n",
       "      <td>Not what the picture describes</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>I bought this steak for my father in law for C...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Not Helpful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Main Title  \\\n",
       "0  Product Reviews Archive January 2016   \n",
       "1  Product Reviews Archive January 2016   \n",
       "2  Product Reviews Archive January 2016   \n",
       "3  Product Reviews Archive January 2016   \n",
       "\n",
       "                                        Review Title  Rating  \\\n",
       "0  The herbs were great...but the cherry tomatoes...       2   \n",
       "1      Even more useful than regular parchment paper       5   \n",
       "2                        Shake it before you bake it       2   \n",
       "3                     Not what the picture describes       2   \n",
       "\n",
       "   Helpfulness Information                                        Review Body  \\\n",
       "0                88.235294  The herb kit that came with my Aerogarden was ...   \n",
       "1               100.000000  I originally bought this just because it was c...   \n",
       "2                15.384615  If you do it in reverse (bake before shaking),...   \n",
       "3                50.000000  I bought this steak for my father in law for C...   \n",
       "\n",
       "  Sentiments  Helpfulness  \n",
       "0   Negative      Helpful  \n",
       "1    Postive      Helpful  \n",
       "2   Negative  Not Helpful  \n",
       "3   Negative  Not Helpful  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_helpfullness[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c7e39f",
   "metadata": {},
   "source": [
    "Now we create the same kind of document array with the concatenation of review body and text alongside the Helpfulness class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78036f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The herbs were great...but the cherry tomatoes...</td>\n",
       "      <td>Helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Even more useful than regular parchment paper ...</td>\n",
       "      <td>Helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shake it before you bake it If you do it in re...</td>\n",
       "      <td>Not Helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not what the picture describes I bought this s...</td>\n",
       "      <td>Not Helpful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text        Class\n",
       "0  The herbs were great...but the cherry tomatoes...      Helpful\n",
       "1  Even more useful than regular parchment paper ...      Helpful\n",
       "2  Shake it before you bake it If you do it in re...  Not Helpful\n",
       "3  Not what the picture describes I bought this s...  Not Helpful"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_helpfulness = pd.DataFrame({\"Review Text\": df_reviews_sentiments[\"Review Title\"]+\" \"+df_reviews_sentiments[\"Review Body\"]\n",
    "                            ,\"Class\":df_reviews_sentiments[\"Helpfulness\"]})\n",
    "df_text_helpfulness[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66d8e0",
   "metadata": {},
   "source": [
    "Now we create a list of documents to vectorize further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85f5aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_helpfulness = df_text_helpfulness[\"Review Text\"]\n",
    "# the corresponding class labels to use for training\n",
    "target_names_help = df_text_helpfulness[\"Class\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529a1e1",
   "metadata": {},
   "source": [
    "Using the same function for sentiment analysis we clean our document and filter out the unnecessary words, this is similar to what we are getting for sentiment analysis but we are just giving it a different name for easy use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef593d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 9244 filtered document lists\n"
     ]
    }
   ],
   "source": [
    "#fitered documents.\n",
    "filtered_help_doc= filter_doc(documents_helpfulness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81a75b6",
   "metadata": {},
   "source": [
    "Hence we don't need to check the tokenization, token counts and term frequency for the same document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bda66d",
   "metadata": {},
   "source": [
    "For helpfulness analysis, we have used lemmatization as a token technique using TfidfVectorizer vectorization converts which text to feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67302c0c",
   "metadata": {},
   "source": [
    "**Lemming:** Lemming means performing things correctly with the help of a vocabulary and canonical evaluation of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f8ab0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function for lemming\n",
    "def lemma_tokenizer(text):\n",
    "    # use the standard scikit-learn tokenizer first\n",
    "    standard_tokenizer = TfidfVectorizer().build_tokenizer()\n",
    "    tokens = standard_tokenizer(text)\n",
    "    # then use NLTK to perform lemmatisation on each token\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    filtered_tokens=[]\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    lemma_tokens = [lemmatizer.lemmatize(t) for t in filtered_tokens if t not in stopwords]\n",
    "    return lemma_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c31504",
   "metadata": {},
   "source": [
    "### Term Frequency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b87b0",
   "metadata": {},
   "source": [
    "We now define our CountVectorize function based on the tokenizer we created while removing words with a frequency less than 10, we can do higher as well because our general frequency of words is quite high, but to be on the safe side I decided to keep the min_df as 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3997fb17",
   "metadata": {},
   "source": [
    "We also create a vectorized data data set for term frequency analysis and this can be used further for applying ***cross-validation*** as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c98f796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9244, 5030)\n"
     ]
    }
   ],
   "source": [
    "#Vectorization using tfidfvectorization\n",
    "vectorizer_help = TfidfVectorizer(stop_words=\"english\", min_df = 10, tokenizer=lemma_tokenizer)\n",
    "X_data_help = vectorizer_help.fit_transform(filtered_document_senti)\n",
    "print(X_data_help.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3bbd708c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary has 5030 distinct terms\n"
     ]
    }
   ],
   "source": [
    "#count the terms\n",
    "terms_senti = vectorizer_help.get_feature_names()\n",
    "print(\"Vocabulary has %d distinct terms\" % len(terms_senti))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac82b71",
   "metadata": {},
   "source": [
    "**CountVectorizer and TfidfVectorizer comparison**: As CountVectorizer removes the word based on word count while TfidfVectorizer removes it based on vocabulary, we can see a difference in the word count, it is better to use TfidfVectorizer as it keeps the more sensible words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f51e0",
   "metadata": {},
   "source": [
    "### Train and Test Data Creation<br>\n",
    "Now here we create train and test sets with a split of **30%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41ebfb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "train_data_help, test_data_help, train_target_help, test_target_help = train_test_split(filtered_help_doc, target_names_help, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b85c8",
   "metadata": {},
   "source": [
    "### Train and Test Data Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e96e3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6470, 4109)\n"
     ]
    }
   ],
   "source": [
    "#vectorize training data\n",
    "X_train_help = vectorizer_help.fit_transform(train_data_help)\n",
    "print(X_train_help.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b69083bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2774, 4109)\n"
     ]
    }
   ],
   "source": [
    "#vectorize testing data\n",
    "X_test_help = vectorizer_help.transform(test_data_help)\n",
    "print(X_test_help.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a481cf70",
   "metadata": {},
   "source": [
    "We create a vectorized set of documents for the whole filtered document set for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c91475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9244, 5030)\n"
     ]
    }
   ],
   "source": [
    "#vectorize whole data set\n",
    "X_data_help = vectorizer_help.fit_transform(filtered_help_doc)\n",
    "print(X_data_help.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3859a",
   "metadata": {},
   "source": [
    "### Cross Validation \n",
    "<br>So firstly, we will apply the cross-validation technique using KNN, which can help us analyze which value of K might be better to take into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "718d6fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1 - Mean accuracy=0.814\n",
      "K=3 - Mean accuracy=0.809\n",
      "K=5 - Mean accuracy=0.806\n"
     ]
    }
   ],
   "source": [
    "#cross validatio using KNN\n",
    "for k in [1,3,5]:\n",
    "    # create a single classifier\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    # apply 5-fold cross-validation, measuring accuracy each time\n",
    "    acc_scores = cross_val_score(model, X_data_help, target_names_help, cv=5, scoring=\"accuracy\")\n",
    "    # get the mean accuracy across 5 folds\n",
    "    mean_acc = acc_scores.mean()\n",
    "    print(\"K=%d - Mean accuracy=%.3f\" % (k,mean_acc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9033b859",
   "metadata": {},
   "source": [
    "### KNN=3 using hold-out Stratergy<br>\n",
    "We will now build KNN using our test and train set and calculate the accuracy and other methods of accuracy for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e22542a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a model on the document-term matrix created from the original set of documents\n",
    "model_help_KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "model_help_KNN.fit(X_train_help, train_target_help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2f48dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted values\n",
    "predicted_KNN_help = model_help_KNN.predict(X_test_help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "01e17689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.813\n"
     ]
    }
   ],
   "source": [
    "#accuracy check\n",
    "acc_KNN = accuracy_score(test_target_help, predicted_KNN_help)\n",
    "print(\"Classification accuracy = %.3f\" % acc_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99729362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set target values for helpfulness\n",
    "target_categories_help = [\"Helpfull\",\"Not-Helpful\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "065f8e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Helpfull       0.84      0.93      0.88      2145\n",
      " Not-Helpful       0.63      0.41      0.50       629\n",
      "\n",
      "    accuracy                           0.81      2774\n",
      "   macro avg       0.74      0.67      0.69      2774\n",
      "weighted avg       0.80      0.81      0.80      2774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_target_help, predicted_KNN_help, target_names=target_categories_help))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b8764c",
   "metadata": {},
   "source": [
    "As we can see that the accuracy comes out to be similar, for K=3 for cross-validation and hold-out KNN. We can also check that if we increase the folds of the cross validation how our model would work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72e2f8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "cm_KNN = confusion_matrix(test_target_help, predicted_KNN_help)\n",
    "# display it graphically\n",
    "cmd = ConfusionMatrixDisplay(cm_KNN, display_labels=target_categories_help)\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb4be0e",
   "metadata": {},
   "source": [
    "**Comment:** Now, for our train and test split, we can see that the **accuracy is 81.3%** for KNN while the precision is lower for the Not-Helpful class, possibly because the number of Not-Helpful must be lower than the number of Helpful, or perhaps if the deciding percentage was lower, it would have been quite similar. The confusion matrix demonstrates this; we can see that the Helpful class is dominating here and that a greater percentage as a cut-off indicates that the majority of the evaluations were helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aca276",
   "metadata": {},
   "source": [
    "### Pipeline Classification- SVM<br>\n",
    "Pipeline helps in doing every step together, like data preparation(tokenization) and classification. So below we created a pipeline using the SVM classifier and the tokenizer we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ff3b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline using SVM\n",
    "pipeline_SVM_help = Pipeline([\n",
    "    ('vec', TfidfVectorizer(stop_words=\"english\", min_df = 10, tokenizer=lemma_tokenizer)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a77d0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec',\n",
       "                 TfidfVectorizer(min_df=10, stop_words='english',\n",
       "                                 tokenizer=<function lemma_tokenizer at 0x000001C8078C23A0>)),\n",
       "                ('tfidf', TfidfTransformer()), ('clf', SGDClassifier())])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit SVM model\n",
    "pipeline_SVM_help.fit(train_data_help, train_target_help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b589f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.838\n"
     ]
    }
   ],
   "source": [
    "#predict SVM model\n",
    "predicted_SVM_help = pipeline_SVM_help.predict(test_data_help)\n",
    "print(\"Classification accuracy = %.3f\" % accuracy_score(test_target_help, predicted_SVM_help))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28701be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Helpfull       0.86      0.95      0.90      2145\n",
      " Not-Helpful       0.72      0.46      0.57       629\n",
      "\n",
      "    accuracy                           0.84      2774\n",
      "   macro avg       0.79      0.71      0.73      2774\n",
      "weighted avg       0.83      0.84      0.82      2774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report to show all the accuracy metrics\n",
    "print(classification_report(test_target_help, predicted_SVM_help, target_names=target_categories_help))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0dd7338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEHCAYAAABY/HZ4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlN0lEQVR4nO3deZgU1b3/8feHfRUFBJFFwKAGuYpKjEs0uNy4xF9cohHjdYu5iNGrMSa5Llm8ejGLGuOSaDQa1BiVxHhd4k5co0ZRCeKCgKCMIMoiIiIyM9/fH1WDzdDT04OzdHV/Xs9TD1WnTlWd6tZvnzl16hxFBGZmlk3t2roAZma24RzEzcwyzEHczCzDHMTNzDLMQdzMLMMcxM3MMqxDWxegHPXt3T6GDu7Y1sWwJnh9ere2LoI1wces5JNYrc9yjv326h5LltYUlff56asfiIj9G9ovaTBwI7AZUAtcExGXSeoN3AYMBeYB34iIZekxZwMnAjXAaRHxQJq+EzAJ6ArcC5weBfqCO4i3gKGDO/LsA4PbuhjWBPttPrqti2BN8M+Y8pnPsXhpDf98YFBReTsOmNO3kSzVwJkR8YKknsDzkh4CjgemRMTPJZ0FnAX8t6SRwDhgW2Bz4GFJW0VEDXAVMB54hiSI7w/c19CF3ZxiZhUqqInaopZGzxSxMCJeSNdXAK8CA4GDgRvSbDcAh6TrBwO3RsTqiJgLzAZ2ljQA2Cgink5r3zfmHJOXa+JmVpECqKX531iXNBTYAfgn0D8iFkIS6CX1S7MNJKlp16lK09ak6/XTG+QgbmYVq5bGa9mpvpKm5mxfExHX1M8kqQdwO/DdiPhAarDZPt+OKJDeIAdxM6tIQbCmiKaS1OKIGFMog6SOJAH85oj4a5q8SNKAtBY+AHg3Ta8Cch+cDQIWpOmD8qQ3yG3iZlaRAqghiloao6TKfR3wakT8KmfXXcBx6fpxwJ056eMkdZY0DBgBPJs2vayQtEt6zmNzjsnLNXEzq1jN2Ca+O3AM8JKkaWnaOcDPgcmSTgTeAo4AiIiXJU0GXiHp2XJK2jMF4GQ+7WJ4HwV6poCDuJlVqABqmmko7oh4kvzt2QD7NHDMRGBinvSpwKhir+0gbmYVq+gW8RLmIG5mFSmKbO8udQ7iZlaRImBN9mO4g7iZVSpR02AzdnY4iJtZRQqg1jVxM7Psck3czCyjkpd9HMTNzDIpgDWR/ZfWHcTNrCIFoqYMRh5xEDezilUbbk4xM8skt4mbmWWaqHGbuJlZNiUz+ziIm5llUoT4JNq3dTE+MwdxM6tYtW4TNzPLpuTBpptTzMwyyg82zcwyyw82zcwyrqYMXvbJ/s+QmdkGCMSa6FDU0hhJ10t6V9KMnLTbJE1Ll3l1EyhLGippVc6+q3OO2UnSS5JmS7o8nfG+INfEzawiNfODzUnAlcCNa88fcWTduqRLgOU5+edExOg857kKGA88A9wL7E8js927Jm5mFSkQNVHc0ui5Ih4Hlubbl9amvwHcUugckgYAG0XE0xERJD8IhzR2bQdxM6tYtbQravmM9gAWRcSsnLRhkl6U9JikPdK0gUBVTp6qNK0gN6eYWUWKoCldDPtKmpqzfU1EXFPksUexbi18ITAkIpZI2gn4P0nbQt43jxqdQM5B3MwqUvJgs+jX7hdHxJimXkNSB+AwYKe1141YDaxO15+XNAfYiqTmPSjn8EHAgsau4eYUM6tYNbQravkM9gVei4i1zSSSNpXUPl0fDowA3oiIhcAKSbuk7ejHAnc2dgEHcTOrSIGojeKWxki6BXga2FpSlaQT013jWP+B5p7AdEn/Av4CTIiIuoeiJwO/B2YDc2ikZwq4OcXMKlhzdTGMiKMaSD8+T9rtwO0N5J8KjGrKtR3EzawiBVDrsVPMzLJKnp7NzCyrAprSO6VkOYibWUWKkJtTzMyyzOOJm5llVDKeuNvEzcwyyjP7mJllVtLF0DVxM7NMauLYKSXLQdzMKpbn2DQzy6hkKFo3p5iZZZbbxM3MMioZxdDNKZZh777dkYtOH8KydzuidsGB/7GEQ7+9mA+WtefCCUNZVNWJ/oM+4dzfzaPnxjW89mI3LvvBYCB5sn/Mme+w+wHJ3K/nfHM4S9/tSE01jPriSk69sIr22X9mVNK+96u3+OK+K3h/cQdO2ntrAPY46H2OOfMdBo9YzWkHjmDW9G4A7LjnCr51zkI6dAyq14hrLxjAv/7Rsy2L3+aS1+6zH8RL/g4kfVhv+3hJVzZyTKN50ny3SJou6YwCecZKuqcp582K9h2C8T9ZwO8ff43L7pnF3ZP68ubrnZl8ZT92+NIK/vCPV9nhSyu47cp+AAzdehVX3j+Tqx6eycSb53DZDwdRU52c69zfzePqh2dyzSMzWb6kA0/cvXHb3ViFePC23px79LB10ua91oXzvz2Ul57pvk768qXt+clxw5iwz9ZcdPpgfnj5W61Z1BKV1MSLWUpZaZeuBUnaDNgtIraLiEvbujxtoU//akZstwqAbj1qGfy51Sxe2JGnH+jFvt9Ixqjf9xtLefr+XgB06Ra0T/92W7O6HcppTuzesxaAmmqo/kT5Zwu0ZjXjnz1YsWzdP6bnz+5C1Zwu6+WdM6MbSxd1BODNmV3o1Dno2Km2VcpZympRUUspy3QQT6c5ul3Sc+mye548kyRdLekJSa9LOijd9SDQT9I0SXtIelTSmPSYvpLmteKttLl35ndizoyubLPjRyxb3JE+/ZMqdp/+1by/5NNA8doL3fjPsVtz0t5bc9ovqtYGdYBzjhrOkduNomuPWvY46P1WvgMr1pe+upw5L3dlzSeZ/t//M6vrnVLMUsqy0CbeVdK0nO3ewF3p+mXApRHxpKQhwAPA5/OcYyjwZWBL4BFJnwO+BtwTEaMBpNL+olrSqpXtuODbQ5lw/ttra9QN2WbHj7j20Zm8NaszF50+hC/s9QGduiQTcl94yxt88rH4+albMO3JHuz05Q8Lnsta3xZbfcyJ5y7knKOGt3VRSkKpN5UUIwtBfFVdoIWkXRqom3V6X2BkTgDeSFK+pzWTI6IWmCXpDWAb4P3mLKSk8cB4gCEDs/CxJqrXwAXfHsrehy3jSwcmDyk36buGJYs60Kd/NUsWdWDjPtXrHTdkxGq6dKtl3swubLX9qrXpnboEu35lOU8/0MtBvMT0HfAJP7luLhedPoSFb3Zu6+K0ubo5NrMu6z9D7YBdI2J0ugyMiBV58kUj2wDVfPp5rN+o2IiIuCYixkTEmE37ZKNbRgT86swhDB6xmq+f9N7a9F2+8gEPT+4NwMOTe7Prfklwf+etTmsfZC6q6kjVnC70H/QJq1a2Y8mi5IerphqenbIRgz+3unVvxgrqvlENF9w4lz/8bACvPNe98QMqQADV0a6opZRlp8qY34PAqcBFAJJGR8S0PPmOkHQDMAwYDswENquXZx6wE/AscHgLlbekvPxsd6b8pTfDPr+Kk/dNuqidcPYCjjx1ERMnDOX+W/vQb2DSxRBgxrPdue3KYXToAO3aBf91YRW9+tSw7L0OnHf8cNZ8ImpqYPTuH3LQsYvb8M4qw1m/fZPtdv2QXr2r+ePUV7jpkv6sWNaB7/zv2/TqU80FN81lzstdOPebW/K1Exaz+bBP+OYZi/jmGYsAOHvccJYv6djGd9G2mqs5RdL1wEHAuxExKk07D/hPoK6GdE5E3JvuOxs4EagBTouIB9L0nYBJQFfgXuD0iMhX6Vwr60H8NOA3kqaT3MvjwIQ8+WYCjwH9gQkR8XGeNvCLgcmSjgH+3nJFLh2jvriSBxZMy7vvF5PnrJe27+HL2PfwZeulb7JpNVfc93pzF88a8fPvbJE3/am0N1GuWy7rzy2X9W/pImVLNGtzyiTgSuDGeumXRsTFuQmSRgLjgG2BzYGHJW0VETXAVSTNss+QBPH9gfsKXbjkg3hE9Ki3PYnkAyMiFgNH5jlmbZ7UPyLijHp55gGjcrZfA7bLyfKjNP1R4NEGzmtmGdWck0JExOOShhaZ/WDg1ohYDcyVNBvYOe0Rt1FEPA0g6UbgEBoJ4qXd2GNm1oJq09p4Y8tncGr6QuH1kjZJ0wYC83PyVKVpA9P1+ukFlX0Qj4jjI+IvbV0OMystdZNCFBnE+0qamrOML+ISV5F0ax4NLAQuSdPz/SpEgfSCSr45xcysJQSiurboeuziiBjTeLac80csqluXdC1wT7pZBQzOyToIWJCmD8qTXlDZ18TNzBrSkq/dSxqQs3koMCNdvwsYJ6mzpGHACODZiFgIrJC0i5KeF8cCdzZ2HdfEzawyRfONJy7pFmAsSbNLFfBTYKyk0cmVmAecBBARL0uaDLxC8n7KKWnPFICT+bSL4X008lATHMTNrEI150TJEXFUnuTrCuSfCEzMkz6VnF5zxXAQN7OKVQ6v3TuIm1lFCkRN8Q82S5aDuJlVrFIfK7wYDuJmVpGiGR9stiUHcTOrWOEgbmaWVeUxnriDuJlVLNfEzcwyKgJqah3Ezcwyy71TzMwyKnBziplZhvnBpplZphWevTIbHMTNrGK5OcXMLKOS3ikeO8XMLLPcnGJmlmFuTjEzy6hADuJmZllWBq0pDuJmVqECogxeu8/+o1kzsw0UoaKWxki6XtK7kmbkpF0k6TVJ0yXdIWnjNH2opFWSpqXL1TnH7CTpJUmzJV2eznpfUIM1cUlXUOCvjYg4rdE7MzMrYc3YO2UScCVwY07aQ8DZEVEt6RfA2cB/p/vmRMToPOe5ChgPPAPcC+xPIzPeF2pOmVpMyc3Msqg5x06JiMclDa2X9mDO5jPA4YXOIWkAsFFEPJ1u3wgcwoYG8Yi4od4FukfEykInMzPLjABar3fKt4DbcraHSXoR+AD4UUQ8AQwEqnLyVKVpBTXaJi5pV0mvAK+m29tL+m0TCm9mVpIiiluAvpKm5izji72GpHOBauDmNGkhMCQidgC+B/xJ0kaQd1zcRht8iumd8mtgP+AugIj4l6Q9izjOzKyEqSm9UxZHxJgmX0E6DjgI2Cci+TmIiNXA6nT9eUlzgK1Iat6Dcg4fBCxo7BpF9U6JiPn1kmqKOc7MrKRFkcsGkLQ/yYPMr0XERznpm0pqn64PB0YAb0TEQmCFpF3SXinHAnc2dp1iauLzJe0GhKROwGmkTStmZpkVzfdgU9ItwFiSZpcq4KckvVE6Aw+lPQWfiYgJwJ7A+ZKqSSrEEyJiaXqqk0l6unQleaBZ8KEmFBfEJwCXkTSwvw08AJxS5L2ZmZWuZupiGBFH5Um+roG8twO3N7BvKjCqKdduNIhHxGLg6Kac1MwsGyrgjU1JwyXdLem99I2kO9N2HDOzbKstcilhxTzY/BMwGRgAbA78GbilJQtlZtbi6vqJF7OUsGKCuCLipoioTpc/Uh6Df5lZhWtCP/GSVWjslN7p6iOSzgJuJQneRwJ/a4WymZm1rBIP0MUo9GDzeZJbrPtb4qScfQFc0FKFMjNrFSXeVFKMQmOnDGvNgpiZtTaVeU18LUmjgJFAl7q0iLix4SPMzEpcCMpgUohGg7ikn5K8iTSSZHzbA4AnWXfcXDOz7CmDmngxvVMOB/YB3omIE4DtSV4lNTPLthYcO6W1FNOcsioiaiVVp8Mlvgv4ZR8zy74SD9DFKCaIT03nhruWpMfKh8CzLVkoM7MW17qTQrSYYsZO+U66erWk+0mmD5ressUyM2t5Zd07RdKOhfZFxAstUyQzs1ZSzkEcuKTAvgD2buaymJm1qrKuiUfEXq1ZkHIy6/VNOHCvghNbW4npMPSTti6CNYHe7tQ8J6qENnEzs7KUge6DxXAQN7PK5SBuZpZdKvEJH4pRzMw+kvQfkn6Sbg+RtHPLF83MrIU10xubkq5PZz6bkZPWW9JDkmal/26Ss+9sSbMlzZS0X076TpJeSvddns56X1Axr93/FtgVqJsIdAXwmyKOMzMrWYrilyJMAvavl3YWMCUiRgBT0m0kjQTGAdumx/xWUvv0mKuA8cCIdKl/zvUUE8S/GBGnAB8DRMQyoJkeDZuZtaFmmp4tIh4HltZLPhi4IV2/ATgkJ/3WiFgdEXOB2cDOkgaQvEz5dEQEySCDh9CIYtrE16S/EgEgaVNKfupQM7MitOyDzf4RsRAgIhZK6pemDwSeyclXlaatSdfrpxdUTE38cuAOoJ+kiSTD0F5YxHFmZiWtCc0pfSVNzVnGf5bL5kmLAukFFTN2ys2SnicZjlbAIRHxamPHmZmVtGhS75TFETGmiVdYJGlAWgsfQDICLCQ17ME5+QYBC9L0QXnSCyqmd8oQ4CPgbuAuYGWaZmaWbS07nvhdwHHp+nHAnTnp4yR1ljSM5AHms2nTywpJu6S9Uo7NOaZBxbSJ/41Pq/pdgGHATJInq2Zm2dVMbeKSbiGZAa2vpCrgp8DPgcmSTgTeAo4AiIiXJU0GXgGqgVMioiY91ckkPV26AvelS0HFNKf8W73C7si6M9+bmWVScw2AFRFHNbBrnwbyTwQm5kmfCoxqyrWLebBZ/yIvAF9o6nFmZtb8ipko+Xs5m+2AHYH3WqxEZmatpULGTumZs15N0kZ+e8sUx8yslTStd0rJKhjE05d8ekTED1qpPGZmraeca+KSOkREdaFp2szMskqU+cw+JDPa7whMk3QX8GdgZd3OiPhrC5fNzKxllXkQr9MbWEIyp2Zdf/EAHMTNLLuKH6GwpBUK4v3SnikzWP+9/jK4dTOreGX+YLM90IMNHJTFzKzUlXtNfGFEnN9qJTEza21lHsQbHwndzCyrKmC2+7zv/JuZlYuybk6JiPpTDZmZlZdyDuJmZuWu7F+7NzMrWxXQJm5mVrZEefTecBA3s8rlmriZWXaVde8UM7Oy5yBuZpZRZTIpRJPn2DQzKxtR5NIISVtLmpazfCDpu5LOk/R2TvqBOcecLWm2pJmS9tvQW3BN3MwqVjPOdj8TGA1rZ0R7G7gDOAG4NCIuXue60khgHLAtsDnwsKStIqKmqdd2TdzMKlcz1cTr2QeYExFvFshzMHBrRKyOiLnAbGDnJl8JB3Ezq2CK4pYmGgfckrN9qqTpkq6XtEmaNhCYn5OnKk1rMgdxM6tMQTIpRDEL9JU0NWcZn++UkjoBXyOZzhLgKmBLkqaWhcAldVkbKFGTuU3czCpSEydKXhwRY4rIdwDwQkQsAqj7F0DStcA96WYVMDjnuEHAgqJLk8M1cTOrXM3fJn4UOU0pkgbk7DuUZLpLgLuAcZI6SxoGjCCZnL7JXBM3s4qlaL63fSR1A/4dOCkn+ZeSRpP8FMyr2xcRL0uaDLwCVAOnbEjPFHAQN7NK1cyjGEbER0CfemnHFMg/EZj4Wa/rIG5mFctjp5iZZVg5vHbvIG5mlcs1cTOzjNqwF3lKjoO4mVUuB3Ezs2xq4ss+JctB3MwqlmqzH8UdxM2sMnm2eysnHTvW8MvLHqNjp1rat6/lyccGcfOkkRxzwsvssvsCakMsX9aZX/1iDEuXdGXsvm/x9SNfX3v8sOHLOW38PrwxZ+O2u4kK07ffKs788Yts0mc1tbVw/11bcNfk4Qz73HJO+eFLdO1azaKF3bjovB1Y9VFHRn/hPU44+VU6dKylek07rvvNSKY/37etb6NNlUMXQ0Uzvna6zomlAH4VEWem298HekTEeQWOOQR4PSJeaWD/hxHRI2f7eGBMRJxa4JyN5knz3UIyQPsfIuLSBvKMBb4fEQcVOlevrgNi16HHF8pSgoIuXWr4+OMOtG9fy8VXPMrVV2zPW29uxKqPOgLwtcNmM2SLD7jy0h3XOXLosOX8+H+f4sSjD2iDcjcPrf6krYvQZJv0+ZjefT5mzusb07VbNZdd/zgXnPUFvvfjF7nuipHMmNaXf//qW/Tf/CP+eO02DN9qOe8v7czSxV3YYvgHnH/pPznu4H9v69vYIE+9fTPLV7+TbyTAovXoPTi22/e7ReV9+s/ff77IAbBaXUsOgLUaOExSU37qDwFGtkxxGiZpM2C3iNiuoQBe/sTHHyd/mHXoUEv79gFobQAH6NKlmny/+V/eZz6P/X3w+jusRS1b0oU5r28MwKqPOjD/zR702fRjBg1ZyYxpydvfLz63KbuPXQjAG6/3YuniLgC8+UZPOnWqoUPHDRquo2y00Hjiraolg3g1cA1wRv0dkraQNCUdKH2KpCGSdiMZh/eidC66LZtyMUmbSrpd0nPpsnuePJMkXS3pCUmvS6qrUT8I9Euvu4ekRyWNSY/pK2leE+89k9q1C6649mH+dMc9vPh8P2a+2huAY0+cwQ233cvYfedz0x+2Xe+4PcdW8dgUB/G21G+zjxg+YjkzX96YN9/oyS57JCOgfmnvBfTtt2q9/LvvtZA3Xu9F9Zr2rV3U0hFARHFLCWvpoWh/AxwtqVe99CuBGyNiO+Bm4PKIeIpkeMYfRMToiJiT53xdcycjBc7P2XcZyVx2XwC+Dvy+gTINBb4MfBW4WlIXkh+POel1n9iQG5U0vm7A+E+qP9qQU7S52lrxX/+5L8cecSBbbbOMLYYuB+DG60Zx3JEH8ujDg/l/h677tWz9+aWsXt2eN+fV/4qttXTpWs25F07l2stGseqjjvz6wu356tfnctn1j9O1WzXV1ev+bz5k2ApO+M6rXPHL7dqoxKVDtcUtpaxFH2xGxAeSbgROA3KrA7sCh6XrNwG/LPKUqyJidN1GXXt3urkvMFJa20y2kaSeec4xOSJqgVmS3gC2Ad4v8voNiohrSP7yoFfXAaX9092IlSs78dK0vuy086J1gvOjUwZz3s+e4uZJn7Z47bnXfB51U0qbad++lnMunMojDw7kqceSoaur3uzJj7+7KwCbD/6QL+z27tr8fTZdxY9+9hyXnL8D77zdvU3KXCrKpZ94a0wK8WvgRKDQfzHrfZSSBufUuicUcZ12wK5pbXp0RAyMiBVFXCvf11jNp59NlyKunXkb9VpN9+7Jw71OnWoYvdO7VL3Vk80HfvoRfnG3hVS99envohTsMfZtHv/7oFYvrwEEp5/zL+bP68H/3fpp62OvTVYDyfcz7vhZ3HfHFgB077GG8y5+lklXb8OrL/VukxKXlGKbUkq8OaXFuxhGxNJ08PMTgevT5KdIJhO9CTgaeDJNXwH0TI+bTzIvXbEeBE4FLgKQNDoipuXJd4SkG4BhwHBgJrBZvTzzgJ1IZto4vAllyKzefT7mzLOeo127QO3giUcH8ewzAzj3f55m4OAPiVp4d1G3dXqmjNpuMYvf68o7C3sUOLO1lJHbLWWfA6qYO7snV0x6DIAbfrcNmw9eyUGHzQPgqccG8NDfkr+UDjp8LpsPWslRx8/iqONnAfCjM3Zh+bLObVL+UlAONfGW7GK4tjugpP7AXOCXEXGepKEkAb0v8B5wQkS8lT6MvJakZ8vh9dvFC3UxTHvB/Ab4PMmP0+MRMaFenknAMpImmP7A9yLinrQ890TEqPS82wCTgQ+BvwP/ERFDy7uLYWXLYhfDStYcXQx7bjwodtjz9KLyPnH3D0u2i2GL1cRzg206WWi3nO15wN55jvkHBboY5p4z3Z4ETErXFwNH5jlmbZ7UPyLijHp55gGjcrZfA3Kf+vwoTX8UeLSh8plZtpRDTdxvbJpZZQqgJvtRvKJmu4+I4yPiL21dDjMrDc35so+keZJeSjtjTE3Tekt6SNKs9N9NcvKfLWm2pJmS9tvQe6ioIG5mto7m752yV9o7rq79/CxgSkSMAKak20gaSdK5Y1tgf+C3kjbozSsHcTOrWK3w2v3BwA3p+g0kQ4vUpd8aEasjYi4wG9h5Qy7gIG5mlSmasBR/xgclPS9pfJrWPyIWAqT/9kvTBwLzc46tStOazA82zawiCVDxDzb71rVzp65J39LOtXtELJDUD3hI0muNXL6+DarzO4ibWcVS8e3dixvrJx4RC9J/35V0B0nzyCJJAyJioaQBQN0YCFVA7ngVg4AFTSp8ys0pZlaZmrE5RVL3urGaJHUHvgLMIBnU77g023HAnen6XcA4SZ0lDQNGkLwh3mSuiZtZhWrWcVH6A3ekA/B1AP4UEfdLeg6YLOlE4C3gCICIeDkdjuQVkrGaTomIDRrc3UHczCpWc72xGRFvANvnSV8C7NPAMROBiZ/12g7iZla5SnyEwmI4iJtZZYom9U4pWQ7iZla5sh/DHcTNrHI1oYthyXIQN7PK5SBuZpZRAZT4JMjFcBA3s4okws0pZmaZVpv9qriDuJlVJjenmJllm5tTzMyyzEHczCyrmnUArDbjIG5mlalMZrt3EDeziuU2cTOzLHMQNzPLqABqHcTNzDLKDzbNzLLNQdzMLKMCqMn+K5ue7d7MKlRA1Ba3NELSYEmPSHpV0suSTk/Tz5P0tqRp6XJgzjFnS5otaaak/Tb0LlwTN7PK1XzNKdXAmRHxgqSewPOSHkr3XRoRF+dmljQSGAdsC2wOPCxpqw2Z8d41cTOrTHW9U4pZGjtVxMKIeCFdXwG8CgwscMjBwK0RsToi5gKzgZ035DYcxM2sckUUtzSBpKHADsA/06RTJU2XdL2kTdK0gcD8nMOqKBz0G+QgbmaVq/gg3lfS1JxlfL7TSeoB3A58NyI+AK4CtgRGAwuBS+qy5ivNhtyC28TNrDJFQE3RTdCLI2JMoQySOpIE8Jsj4q/JJWJRzv5rgXvSzSpgcM7hg4AFxRYml2viZla5mqk5RZKA64BXI+JXOekDcrIdCsxI1+8CxknqLGkYMAJ4dkNuwTVxM6tczdc7ZXfgGOAlSdPStHOAoySNJmkqmQeclFw2XpY0GXiFpGfLKRvSMwUcxM2sYhXX86SoM0U8Sf527nsLHDMRmPhZr+0gbmaVKSCKeJGn1DmIm1nlKoPX7h3EzawyRUCtg7iZWXZ5FEMzs+wK18TNzLLKk0KYmWWXp2czM8uuAKL41+5LloO4mVWmiKImfCh1DuJmVrHCzSlmZhlWBjVxRRk8nS01kt4D3mzrcrSAvsDiti6ENUm5fmdbRMSmn+UEku4n+XyKsTgi9v8s12spDuJWNElTGxtT2UqLv7Py5/HEzcwyzEHczCzDHMStKa5p6wJYk/k7K3NuEzczyzDXxM3MMsxBvAJI+rDe9vGSrmzkmEbzpPlukTRd0hkF8oyVdE9TzlvOJIWkS3K2vy/pvEaOOUTSyAL7S+Y7ttbll31sg0naDNgtIrZo67JkzGrgMEk/i4hi+3AfAtxDMrFuq/F3XPpcE69wkjaVdLuk59Jl9zx5Jkm6WtITkl6XdFC660Ggn6RpkvaQ9KikMekxfSXNa8VbyZJqkgeO69VsJW0haUpa850iaYik3YCvAReln/WWTbmYv+Py5pp4ZegqaVrOdm/grnT9MuDSiHhS0hDgAeDzec4xFPgysCXwiKTPkQSWeyJiNICUb7Jva8BvgOmSflkv/Urgxoi4QdK3gMsj4hBJd5F81n9p4Hz+jiuUg3hlWFX3PyEkbaFA3Vt8+wIjc/7n3EhSzzznmBzJ1OCzJL0BbAO831IFLncR8YGkG4HTgFU5u3YFDkvXbwLqB/mG+DuuUA7i1g7YNSJyA0m+Glf9vqj5+qZW82kTXZdmKV15+zXwAvCHAnnW+5wlDQbuTjevjoirG7mOv+My5jZxexA4tW5D0ugG8h0hqV3aHjscmJknzzxgp3T98GYsY1mKiKXAZODEnOSngHHp+tHAk+n6CqBnetz8iBidLo0FcPB3XNYcxO00YEz6IO0VYEID+WYCjwH3ARMi4uM8eS4GTpb0FMWPDlfpLmHdz+o04ARJ04FjgNPT9FuBH0h6sakPNvF3XNb8xqY1StIkCj9Us4zzd5xdrombmWWYa+JmZhnmmriZWYY5iJuZZZiDuJlZhjmIW6uTVJOOxTFD0p8ldfsM55ok6fB0/feNjPQ3Nh2HpKnXmCdpve50DaXXy/Nhof158p8n6ftNLaNVLgdxawur0hdVRgGfUK/fsqT2G3LSiPh2RBQa5W8s0OQgblbKHMStrT0BfC6tJT8i6U/AS5LaS7ooHXVvuqSTAJS4UtIrkv4G9Ks7Ub0R9vaX9IKkf6WjAQ4l+bE4I2dEvryj+0nqI+nB9MWa3wGNjvok6f8kPS/pZUnj6+27JC3LFEmbpmlbSro/PeYJSds0y6dpFcdjp1ibkdQBOAC4P03aGRgVEXPTQLg8Ir4gqTPwD0kPAjsAWwP/BvQnGV/7+nrn3RS4FtgzPVfviFgq6Wrgw4i4OM33J/KP7vdT4MmIOF/SV4F1gnIDvpVeoyvwnKTbI2IJ0B14ISLOlPST9NynkgxFOyEiZkn6IvBbYO8N+BitwjmIW1vIHTb1CeA6kmaOZyNibpr+FWC7uvZuoBcwAtgTuCUiaoAFkv6e5/y7AI/XnSsdoySfhkb325N0JMGI+JukZUXc02mSDk3XB6dlXQLUArel6X8E/iqpR3q/f865ducirmG2HgdxawvrDJsKa0fUW5mbBPxXRDxQL9+B5B9db51sReSBwqP7Ff0WnKSxJD8Iu0bER5IepeER/iK97vv1PwOzDeE2cStVD5AMtNQRQNJWkroDjwPj0jbzAcBeeY59GviypGHpsb3T9LUjAaYaGt3vcZIRBJF0ALBJI2XtBSxLA/g2JH8J1GnHp6P9fZOkmeYDYK6kI9JrSNL2jVzDLC8HcStVvydp735B0gzgdyR/Od4BzAJeAq4iGXVvHRHxHkk79l8l/YtPmzPuBg6te7BJw6P7/Q+wp6QXSJp13mqkrPcDHdKRBy8AnsnZtxLYVtLzJG3e56fpRwMnpuV7GTi4iM/EbD0eO8XMLMNcEzczyzAHcTOzDHMQNzPLMAdxM7MMcxA3M8swB3EzswxzEDczyzAHcTOzDPv/YAkEwCOFjgQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "cm_SVM = confusion_matrix(test_target_help, predicted_SVM_help)\n",
    "# display it graphically\n",
    "cmd = ConfusionMatrixDisplay(cm_SVM, display_labels=target_categories_help)\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389c561",
   "metadata": {},
   "source": [
    "Same as sentiment Analysis, SVM worked better than KNN while analyzing Helpfulness for this dataset. The **accuracy is 83.8%**, and we can see that it predicted the \"Not-helpful\" class more accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab6cd3",
   "metadata": {},
   "source": [
    "There are other classifications as well which we can try and test to see which fits better to our data set, we will be using the same tokenizer, ie. lemming, and same vectorizer that is TFIDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92afe898",
   "metadata": {},
   "source": [
    "### Pipeline Classification- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df32628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline using Logistic regression\n",
    "pipeline_LR = Pipeline([\n",
    "    ('vec', TfidfVectorizer(stop_words=\"english\", min_df = 10, tokenizer=lemma_tokenizer)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ba7f67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec',\n",
       "                 TfidfVectorizer(min_df=10, stop_words='english',\n",
       "                                 tokenizer=<function lemma_tokenizer at 0x000001C8078C23A0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LogisticRegression(random_state=0))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic regression fit\n",
    "pipeline_LR.fit(train_data_help, train_target_help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "126e8225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.822\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression prediction\n",
    "predicted_LR_Help = pipeline_LR.predict(test_data_help)\n",
    "print(\"Classification accuracy = %.3f\" % accuracy_score(test_target_help, predicted_LR_Help))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea25a5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "cm_LR = confusion_matrix(test_target_help, predicted_LR_Help)\n",
    "# display it graphically\n",
    "cmd = ConfusionMatrixDisplay(cm_LR, display_labels=target_categories_help)\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f90f4f",
   "metadata": {},
   "source": [
    "We can see that, Logistic Regression accuracy was less than SVM but greater than KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802288ba",
   "metadata": {},
   "source": [
    "**Sentiment and Helpfulness Comparison:** We can see that KNN performed more accurately for helpfulness analysis than sentiment analysis, while SVM performed better for Sentiment Analysis than helpfulness, which may be attributed to three factors: a high train-test split %, the usage of TFIDvectorizer, and the use of lemming as a tokenization method. <br>\n",
    "**We may even claim that the number of positive ratings is exactly related to the helpfulness quotient because more ratings equal more help.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7994f0",
   "metadata": {},
   "source": [
    "Few comparison points for different types of Classifiers:\n",
    "1. SVM performed best in all the cases, as SVM usually deals with creating boundaries that works best for text classifications\n",
    "2. KNN and Logistic Regression also had good accuracies but they would work best with models where there are dependent variables.\n",
    "3. KNN is easy to model while others are complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c906e07",
   "metadata": {},
   "source": [
    "## Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd8a09",
   "metadata": {},
   "source": [
    "### Accuracy Comparision for Sentiment and Helpfulness Analysis:\n",
    "\n",
    "| Classifiers      | Sentiment Analysis | Helpfulness Analysis |\n",
    "| ----------- | ----------- |-----------------|\n",
    "| KNN      | Less       | More |\n",
    "| SVM   | More       | Less |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33695bc4",
   "metadata": {},
   "source": [
    "1. TFIDFVectorization is better than CountVectorization.\n",
    "2. Lemming is better than Stemming.\n",
    "3. SVM performed the best for both data sets.\n",
    "4. Train-test split of 30% gave more accuracy for KNN\n",
    "5. Cross-fold validation gave less accuracy than the hold-out strategy.\n",
    "6. Cross-fold validation with more folds will give a more accurate model but a not ideal scenario that may work better for larger data sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
